{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe1d95ad-2ec1-44f7-94b0-d55241978782",
   "metadata": {},
   "source": [
    "## üìö Libraries and Tools I Used\n",
    "\n",
    "- **OpenCV (`cv2`)**  \n",
    "  I used OpenCV to handle the webcam feed, process images, and show live video windows. It‚Äôs a go-to library for most computer vision tasks.\n",
    "\n",
    "- **MediaPipe (`mediapipe`)**  \n",
    "  MediaPipe‚Äôs Face Mesh module lets me detect 468 detailed facial landmarks in real-time, which is perfect for measuring facial asymmetry precisely.\n",
    "\n",
    "- **NumPy (`numpy`)**  \n",
    "  NumPy helps me with numerical operations like calculating averages and manipulating arrays of landmark coordinates efficiently.\n",
    "\n",
    "- **Time (`time`)**  \n",
    "  I used the time module to add countdowns and delays, like waiting a few seconds before taking a snapshot to make sure the face is stable.\n",
    "\n",
    "---\n",
    "\n",
    "Using these libraries together, I‚Äôm able to capture video, detect and analyze the face accurately, and control the timing of the scan.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2bc485af-f31f-462f-9726-10f082ee486e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15a6878d-ed21-4216-8c17-9ea2cc3be45f",
   "metadata": {},
   "source": [
    "## ‚öôÔ∏è Setting Up MediaPipe Face Mesh\n",
    "\n",
    "- **`mp_face_mesh` & `mp_drawing`**  \n",
    "  I used these shortcuts from MediaPipe to access the face mesh detection and drawing tools. They help me detect facial landmarks and visualize them on the video feed.\n",
    "\n",
    "- **`drawing_spec`**  \n",
    "  This defines how the landmarks look when drawn ‚Äî I chose small circles with thin outlines to keep the visualization clear but not distracting.\n",
    "\n",
    "- **Initializing `face_mesh`**  \n",
    "  Here, I set up the Face Mesh detector with some key parameters:  \n",
    "  - `static_image_mode=False` because I‚Äôm working with live video, not still images.  \n",
    "  - `max_num_faces=1` to focus on detecting only one face at a time (the patient).  \n",
    "  - `refine_landmarks=True` to get more precise points around important features like eyes and lips.  \n",
    "  - Detection and tracking confidence thresholds are set to 0.5 to balance accuracy and speed.\n",
    "\n",
    "- **Symmetric Landmark Pairs**  \n",
    "  To calculate facial asymmetry, I selected pairs of landmarks on opposite sides of the face that should roughly mirror each other:  \n",
    "  - Outer and inner eye corners, mouth corners, and cheeks.  \n",
    "  - Comparing these pairs lets me measure how symmetrical the face is.\n",
    "\n",
    "*Note:* I only included a few pairs for simplicity, but I plan to add more to improve accuracy later.\n",
    "\n",
    "---\n",
    "\n",
    "This setup lets me detect detailed facial landmarks in real time and compare key points to assess asymmetry.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "662eb828-8e3d-4228-abb5-f36b229b4241",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === MediaPipe setup ===\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "drawing_spec = mp_drawing.DrawingSpec(thickness=1, circle_radius=1)\n",
    "\n",
    "# Initialize Face Mesh\n",
    "face_mesh = mp_face_mesh.FaceMesh(\n",
    "    static_image_mode=False,\n",
    "    max_num_faces=1,\n",
    "    refine_landmarks=True,\n",
    "    min_detection_confidence=0.5,\n",
    "    min_tracking_confidence=0.5\n",
    ")\n",
    "\n",
    "# Symmetric landmark pairs for comparison\n",
    "# TODO: Expand list for better accuracy\n",
    "symmetric_pairs = [\n",
    "    (33, 263),   # outer eye corners\n",
    "    (133, 362),  # inner eye corners\n",
    "    (61, 291),   # mouth corners\n",
    "    (199, 429),  # cheek points\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6815d720-4c9f-4429-9f8f-9eece0afe62c",
   "metadata": {},
   "source": [
    "## üîç Calculating Facial Asymmetry\n",
    "\n",
    "I wrote this function to measure how asymmetrical the face is by comparing pairs of symmetric landmarks.\n",
    "\n",
    "Here‚Äôs how it works:\n",
    "\n",
    "- For each pair of corresponding points on the left and right sides of the face, I first convert their normalized coordinates to pixel values based on the image width and height.\n",
    "\n",
    "- Since the right side landmarks need to be compared against the left side, I **mirror** the right points horizontally across the vertical midline of the face.\n",
    "\n",
    "- Then, I calculate the Euclidean distance between each left landmark and its mirrored right counterpart ‚Äî basically, how far apart they are in pixels.\n",
    "\n",
    "- Finally, I average these distances across all pairs to get a single **asymmetry score**: the higher the score, the more asymmetrical the face.\n",
    "\n",
    "This method gives me a straightforward way to quantify facial asymmetry using precise landmark positions.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d810a78a-5197-473b-9bb3-f2d217dfbffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_asymmetry(landmarks, img_width, img_height):\n",
    "    \"\"\"\n",
    "    Calculate average difference between symmetric facial landmarks.\n",
    "    The right-side landmarks are mirrored across the vertical midline for comparison.\n",
    "    \"\"\"\n",
    "    total_diff = 0\n",
    "    for left_idx, right_idx in symmetric_pairs:\n",
    "        left_point = np.array([\n",
    "            landmarks[left_idx].x * img_width,\n",
    "            landmarks[left_idx].y * img_height\n",
    "        ])\n",
    "        right_point = np.array([\n",
    "            landmarks[right_idx].x * img_width,\n",
    "            landmarks[right_idx].y * img_height\n",
    "        ])\n",
    "        \n",
    "        # Mirror the right point horizontally\n",
    "        mid_x = img_width / 2\n",
    "        mirrored_right = np.array([2 * mid_x - right_point[0], right_point[1]])\n",
    "        \n",
    "        diff = np.linalg.norm(left_point - mirrored_right)\n",
    "        total_diff += diff\n",
    "    \n",
    "    return total_diff / len(symmetric_pairs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa8b6028-74b8-4879-9147-9f96567f74d7",
   "metadata": {},
   "source": [
    "## üéØ Checking If the Face Is Centered\n",
    "\n",
    "To make sure the face is properly aligned before taking a snapshot, I wrote this function to check if the face is horizontally centered in the camera frame.\n",
    "\n",
    "Here‚Äôs what I do:\n",
    "\n",
    "- I take all the detected facial landmarks and calculate their average x-coordinate (left to right position) ‚Äî this gives me an approximate midpoint of the face.\n",
    "\n",
    "- Since MediaPipe gives normalized coordinates (from 0 to 1), I convert this average to pixels based on the image width.\n",
    "\n",
    "- Then, I compare the face midpoint to the center of the image frame.\n",
    "\n",
    "- If the face midpoint is within a certain threshold (default 10% of the frame width) from the center, I consider the face centered.\n",
    "\n",
    "This helps me prompt the user to adjust their position for a better scan if needed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2b60bbb0-011c-44ed-8800-8dab7e09f033",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_face_centered(landmarks, img_width, threshold=0.1):\n",
    "    \"\"\"\n",
    "    Check if the face is horizontally centered within a threshold.\n",
    "    - landmarks: list of face landmarks from MediaPipe\n",
    "    - img_width: width of the image/frame\n",
    "    - threshold: allowed deviation as fraction of image width (default 10%)\n",
    "    \n",
    "    Returns True if centered, False otherwise.\n",
    "    \"\"\"\n",
    "    # Calculate average x of all landmarks (face midpoint)\n",
    "    x_coords = [lm.x for lm in landmarks]\n",
    "    avg_x = np.mean(x_coords)  # normalized 0 to 1\n",
    "\n",
    "    # Convert to pixel coordinate\n",
    "    face_mid_x = avg_x * img_width\n",
    "    center_x = img_width / 2\n",
    "\n",
    "    # Check if within threshold distance from center\n",
    "    return abs(face_mid_x - center_x) < threshold * img_width"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dd52f07-8e92-47cc-81d7-995b788cc83a",
   "metadata": {},
   "source": [
    "## üìä Interpreting the Asymmetry Score\n",
    "\n",
    "After calculating the asymmetry score, I use this function to give a simple interpretation based on clinically inspired thresholds:\n",
    "\n",
    "- Scores **0‚Äì30 px** mean the face is very symmetrical, which is normal.  \n",
    "- Scores between **30‚Äì80 px** indicate mild asymmetry, which is typical for most people.  \n",
    "- Scores from **80‚Äì150 px** suggest noticeable asymmetry that might warrant further attention.  \n",
    "- Scores above **150 px** signal significant asymmetry, which could be a sign of neurological issues and means the person should see a neurologist immediately.\n",
    "\n",
    "This helps translate the raw number into something meaningful and actionable for the user.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6611c1bc-0f4a-45c2-bd0e-b58914a2303a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def interpret_asymmetry_score(score):\n",
    "    \"\"\"\n",
    "    Interpretation of the asymmetry score in pixels.\n",
    "    Clinical-inspired thresholds:\n",
    "    0‚Äì30 px    : Very symmetrical\n",
    "    30‚Äì80 px   : Mild asymmetry (typical in most human faces)\n",
    "    80‚Äì150 px  : Noticeable asymmetry\n",
    "    150+ px    : Significant asymmetry\n",
    "    \"\"\"\n",
    "    if score < 30:\n",
    "        return \"Very symmetrical face detected.\"\n",
    "    elif score < 80:\n",
    "        return \"Mild asymmetry detected (typical in most human faces).\"\n",
    "    elif score < 150:\n",
    "        return \"Noticeable asymmetry detected.\"\n",
    "    else:\n",
    "        return \"Significant asymmetry detected ‚Äî consult a neurologist immediately.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7f43f218-4dbb-4549-ad72-15e72ae118e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_welcome_screen():\n",
    "    # Create a blank black image\n",
    "    height, width = 480, 640\n",
    "    welcome_img = np.zeros((height, width, 3), dtype=np.uint8)\n",
    "\n",
    "    # Add welcome text\n",
    "    lines = [\n",
    "        \"Welcome to the Virtual Neurologist!\",\n",
    "        \"\",\n",
    "        \"This AI system will check your face for neurological\",\n",
    "        \"symptoms by detecting facial asymmetry.\",\n",
    "        \"\",\n",
    "        \"Instructions:\",\n",
    "        \"- Sit comfortably in front of your camera.\",\n",
    "        \"- Make sure your face is well lit and visible.\",\n",
    "        \"- Follow on-screen prompts to align your face.\",\n",
    "        \"\",\n",
    "        \"Press any key to begin...\"\n",
    "    ]\n",
    "\n",
    "    y0, dy = 50, 30\n",
    "    for i, line in enumerate(lines):\n",
    "        y = y0 + i * dy\n",
    "        cv2.putText(welcome_img, line, (30, y),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
    "\n",
    "    # Show image and wait for key press\n",
    "    cv2.imshow(\"Welcome Screen\", welcome_img)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyWindow(\"Welcome Screen\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4d1be906-cc6b-46ef-89a9-284f4656f6b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI Neurologist: Please align your face with the camera.\n"
     ]
    }
   ],
   "source": [
    "# === Interactive AI Neurologist Simulation with Alignment Check ===\n",
    "show_welcome_screen()\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Could not open webcam.\")\n",
    "else:\n",
    "    print(\"AI Neurologist: Please align your face with the camera.\")\n",
    "\n",
    "countdown_started = False\n",
    "countdown_time = 5  # seconds\n",
    "start_time = None\n",
    "snapshot = None\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    results = face_mesh.process(frame_rgb)\n",
    "    img_width = frame.shape[1]\n",
    "\n",
    "    if results.multi_face_landmarks:\n",
    "        landmarks = results.multi_face_landmarks[0].landmark\n",
    "        centered = is_face_centered(landmarks, img_width)\n",
    "\n",
    "        if centered:\n",
    "            if not countdown_started:\n",
    "                start_time = time.time()\n",
    "                countdown_started = True\n",
    "\n",
    "            elapsed = time.time() - start_time\n",
    "            if elapsed < countdown_time:\n",
    "                instruction = \"Hold still, capturing image in...\"\n",
    "                timer_text = f\"{int(countdown_time - elapsed)} seconds\"\n",
    "            else:\n",
    "                snapshot = frame.copy()\n",
    "                break\n",
    "        else:\n",
    "            countdown_started = False\n",
    "            instruction = \"Please center your face in the camera.\"\n",
    "            timer_text = \"\"\n",
    "\n",
    "    else:\n",
    "        countdown_started = False\n",
    "        instruction = \"No face detected. Please position your face in front of the camera.\"\n",
    "        timer_text = \"\"\n",
    "\n",
    "    # Display instructions and timer\n",
    "    cv2.putText(frame, instruction, (30, 50),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2)\n",
    "    if timer_text:\n",
    "        cv2.putText(frame, timer_text, (30, 90),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 255), 2)\n",
    "\n",
    "    # Draw face landmarks if available\n",
    "    if results.multi_face_landmarks:\n",
    "        mp_drawing.draw_landmarks(\n",
    "            image=frame,\n",
    "            landmark_list=results.multi_face_landmarks[0],\n",
    "            connections=mp_face_mesh.FACEMESH_TESSELATION,\n",
    "            landmark_drawing_spec=None,\n",
    "            connection_drawing_spec=drawing_spec\n",
    "        )\n",
    "\n",
    "    cv2.imshow(\"Virtual Neurologist\", frame)\n",
    "\n",
    "    if cv2.waitKey(5) & 0xFF in [ord('q'), ord('Q')]:\n",
    "        break\n",
    "\n",
    "# Process snapshot if taken\n",
    "if snapshot is not None:\n",
    "    frame_rgb = cv2.cvtColor(snapshot, cv2.COLOR_BGR2RGB)\n",
    "    results = face_mesh.process(frame_rgb)\n",
    "\n",
    "    if results.multi_face_landmarks:\n",
    "        for face_landmarks in results.multi_face_landmarks:\n",
    "            mp_drawing.draw_landmarks(\n",
    "                image=snapshot,\n",
    "                landmark_list=face_landmarks,\n",
    "                connections=mp_face_mesh.FACEMESH_TESSELATION,\n",
    "                landmark_drawing_spec=None,\n",
    "                connection_drawing_spec=drawing_spec\n",
    "            )\n",
    "\n",
    "            score = calculate_asymmetry(face_landmarks.landmark,\n",
    "                                        snapshot.shape[1],\n",
    "                                        snapshot.shape[0])\n",
    "            \n",
    "            interpretation = interpret_asymmetry_score(score)\n",
    "\n",
    "            # Display the score and interpretation clearly\n",
    "            cv2.putText(snapshot, f\"Asymmetry Score: {score:.2f}\",\n",
    "                        (10, 40), cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                        1, (0, 0, 255), 2)\n",
    "            cv2.putText(snapshot, interpretation,\n",
    "                        (10, 80), cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                        0.8, (255, 255, 255), 2)\n",
    "            cv2.putText(snapshot, \"Press any key to exit.\",\n",
    "                        (10, snapshot.shape[0] - 30), cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                        0.7, (200, 200, 200), 1)\n",
    "    else:\n",
    "        cv2.putText(snapshot, \"No face detected. Please retry.\",\n",
    "                    (30, 50), cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                    0.8, (0, 0, 255), 2)\n",
    "\n",
    "    cv2.imshow(\"Facial Asymmetry Result\", snapshot)\n",
    "    cv2.waitKey(0)\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84d85fa7-e2f3-4a3b-99d7-c58c5cfac7d9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
